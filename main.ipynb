{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import collate_batch_local_search,split_train_test,collate_batch_ptr\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else  \"cpu\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metric\n",
    "\n",
    "**Gap**: $100*\\frac{model\\_time - optimal\\_time}{optimal\\_time}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = np.load('data/instances.npy')\n",
    "instances_orders = np.load('data/instances_orders_unpadded.npy')\n",
    "\n",
    "X,y = instances,instances_orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpad data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needed for the graph network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import unpad\n",
    "\n",
    "for seq in y:\n",
    "    seq = unpad(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/instances_orders_unpadded.npy',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset,test_dataset = split_train_test(X,y,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving TSP with Local Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_search import test_local_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 1/43 [00:21<14:53, 21.28s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# We only need to test the model on the test set\u001b[39;00m\n\u001b[1;32m      2\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,collate_fn\u001b[38;5;241m=\u001b[39mcollate_batch_local_search) \u001b[38;5;66;03m#Large batch size to leverage the multiprocessing\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtest_local_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TSP_DL/local_search.py:27\u001b[0m, in \u001b[0;36mtest_local_search\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m     24\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mPool() \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 27\u001b[0m                     preds \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlocal_search_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m total_pred_len \u001b[38;5;241m=\u001b[39m total_tour_len_nodes(dm,torch\u001b[38;5;241m.\u001b[39mTensor(preds)\u001b[38;5;241m.\u001b[39mint())\n\u001b[1;32m     31\u001b[0m total_gt_len \u001b[38;5;241m=\u001b[39m total_tour_len_nodes(dm,y)\n",
      "File \u001b[0;32m/opt/conda/envs/instadeep/lib/python3.8/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/instadeep/lib/python3.8/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/instadeep/lib/python3.8/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/instadeep/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/conda/envs/instadeep/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We only need to test the model on the test set\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=256,collate_fn=collate_batch_local_search) #Large batch size to leverage the multiprocessing\n",
    "test_local_search(test_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run this file with your own hyperparameters to launch the training of a Graph Conv Net. The models checkpoints will automatically be saved under 'graphconvnet/ckpts'\n",
    "\n",
    "bs :BATCH SIZE\n",
    "lr : Starting learning rate\n",
    "epochs : Number of epochs for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "3it [00:04,  1.33s/it]^C\n"
     ]
    }
   ],
   "source": [
    "! python train_gcn.py --epochs 3 --bs 32 --lr 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphconvnet.model.gcn_model import ResidualGatedGCNModel\n",
    "from graphconvnet.model.model_utils import test_gcn\n",
    "from utils import collate_batch_gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResidualGatedGCNModel(torch.cuda.FloatTensor, torch.cuda.LongTensor).to(DEVICE)\n",
    "checkpoint = torch.load(\"/home/aymenkallala/TSP_DL/graphconvnet/ckpts/checkpoint_epoch3.pth\")\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                            batch_size=10, #Cannot be larger due to memory concerns (computing beamsearch while generating final preds uses a lot)\n",
    "                            shuffle=True,\n",
    "                            collate_fn=collate_batch_gcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/instadeep/lib/python3.8/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  2, 33, 37,  8, 25, 10,  4,  7, 19, 22,  1, 21, 18, 31, 27, 39, 23,\n",
      "        11, 24, 26, 28,  5, 16, 14, 38, 34, 12, 15, 29, 35,  9, 20, 36,  3, 32,\n",
      "        17, 13, 46, 48, 43, 42, 47, 41, 40, 44, 49, 45, 30,  6],\n",
      "       device='cuda:0')\n",
      "tensor([ 0, 21,  1, 22, 19, 31, 18, 27, 39, 23, 11, 24, 26, 13, 17, 32,  3, 28,\n",
      "         5, 16, 14, 36,  7,  4, 10, 35,  9, 20, 38, 34, 12, 15, 29, 30,  6, 25,\n",
      "         8, 37, 33,  2, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for  (x_edges,\n",
    "    x_edges_values,\n",
    "    x_nodes,\n",
    "    x_nodes_coord,\n",
    "    y_edges,\n",
    "    y_nodes) in test_dataloader:\n",
    "\n",
    "\n",
    "    edge_labels = y_edges.cpu().numpy().flatten()\n",
    "    edge_cw = compute_class_weight(\n",
    "                    \"balanced\", classes=np.unique(edge_labels), y=edge_labels\n",
    "                )\n",
    "    \n",
    "\n",
    "    pred,loss = net.decode(x_edges,x_edges_values,x_nodes,x_nodes_coord,y_edges,edge_cw)\n",
    "\n",
    "    print(pred[0])\n",
    "    print(y_nodes[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 6, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_gcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLongTensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TSP_DL/graphconvnet/architecture/model_utils.py:73\u001b[0m, in \u001b[0;36mtest_gcn\u001b[0;34m(dataloader, net, epoch, dtypeFloat, dtypeLong)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx,batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(dataloader)):\n\u001b[0;32m---> 73\u001b[0m         x_edges,x_edges_values,x_nodes,x_nodes_coord,y_edges,y_nodes\u001b[38;5;241m=\u001b[39mbatch\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(edge_cw) \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     76\u001b[0m             edge_labels \u001b[38;5;241m=\u001b[39m y_edges\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 3)"
     ]
    }
   ],
   "source": [
    "test_gcn(test_dataloader,net,1,torch.cuda.FloatTensor,torch.cuda.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "100it [00:52,  1.96it/s]| epoch   1 |   100/ 3052 batches| gap  139.299 | loss 19666611.92079208\n",
      "200it [01:44,  1.98it/s]| epoch   1 |   200/ 3052 batches| gap  140.689 | loss 19724996.64\n",
      "214it [01:51,  1.96it/s]^C\n",
      "214it [01:51,  1.92it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train_transformernet.py\", line 93, in <module>\n",
      "    main(args)\n",
      "  File \"train_transformernet.py\", line 55, in main\n",
      "    train_transformernet(train_dataloader, net, optimizer,criterion, epoch)\n",
      "  File \"/home/aymenkallala/TSP_DL/transformernet/utils.py\", line 17, in train_transformernet\n",
      "    y_pred,probs,_ = model(x,mask)\n",
      "  File \"/opt/conda/envs/instadeep/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/aymenkallala/TSP_DL/transformernet/transformernet.py\", line 436, in forward\n",
      "    prob_next_node = self.decoder(\n",
      "  File \"/opt/conda/envs/instadeep/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/aymenkallala/TSP_DL/transformernet/transformernet.py\", line 298, in forward\n",
      "    h_t = self.decoder_layers[l](h_t, K_att_l, V_att_l, mask)\n",
      "  File \"/opt/conda/envs/instadeep/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/aymenkallala/TSP_DL/transformernet/transformernet.py\", line 253, in forward\n",
      "    h_t = self.BN_MLP(h_t.squeeze(1))  # size(h_t)=(bsz, dim_emb)\n",
      "  File \"/opt/conda/envs/instadeep/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/instadeep/lib/python3.8/site-packages/torch/nn/modules/normalization.py\", line 190, in forward\n",
      "    return F.layer_norm(\n",
      "  File \"/opt/conda/envs/instadeep/lib/python3.8/site-packages/torch/nn/functional.py\", line 2515, in layer_norm\n",
      "    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "! python train_transformernet.py --epochs 3 --bs 32 --lr 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformernet(dataloader, model, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    total_loss, total_count = 0,0,0\n",
    "    log_interval = 100\n",
    "    running_tour_length = 0\n",
    "    running_gt_length = 0\n",
    "\n",
    "    for idx, (x, y,mask,dm) in tqdm(enumerate(dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        total_count += y.shape[0]\n",
    "\n",
    "        y_pred,probs,_ = model(x,mask)\n",
    "        probs = probs.permute(0, 2, 1)\n",
    "\n",
    "        # Get the loss\n",
    "        loss = criterion(probs,y)\n",
    "        total_loss  += loss.item()\n",
    "        # Do back propagation\n",
    "        loss.backward()\n",
    "        # Clip the gradients at 0.1\n",
    "        #nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        # Do an optimization step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute the tour lengths\n",
    "        running_tour_length += total_tour_len_nodes(dm, y_pred)\n",
    "        running_gt_length += total_tour_len_nodes(dm, y)\n",
    "        \n",
    "        \n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            gap = (\n",
    "                    100 * (running_tour_length - running_gt_length) / running_gt_length\n",
    "                )\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches\"\n",
    "                \"| gap {:8.3f}\".format(epoch, idx, len(dataloader), gap),\n",
    "                f\"| loss {total_loss/total_count}\"\n",
    "            )\n",
    "            running_tour_length,running_gt_length, total_count,total_loss = 0, 0, 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:35,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   100/ 6104 batches| gap  139.900 | loss 39170785.58415841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [00:42,  2.86it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_transformernet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 12\u001b[0m, in \u001b[0;36mtrain_transformernet\u001b[0;34m(dataloader, model, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     10\u001b[0m total_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m y_pred,probs,_ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m probs \u001b[38;5;241m=\u001b[39m probs\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Get the loss\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/instadeep/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/TSP_DL/transformernet/transformernet.py:436\u001b[0m, in \u001b[0;36mTSP_net.forward\u001b[0;34m(self, x, starting_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m h_t \u001b[38;5;241m=\u001b[39m h_start\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nb_nodes):\n\u001b[1;32m    434\u001b[0m \n\u001b[1;32m    435\u001b[0m     \u001b[38;5;66;03m# compute probability over the next node in the tour\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m     prob_next_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m(\n\u001b[1;32m    437\u001b[0m         h_t, K_att_decoder, V_att_decoder, mask_visited_nodes\n\u001b[1;32m    438\u001b[0m     )  \u001b[38;5;66;03m# size(prob_next_node)=(bsz, nb_nodes+1)\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;66;03m# choose node with highest probability\u001b[39;00m\n\u001b[1;32m    441\u001b[0m     idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(prob_next_node, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# size(query)=(bsz,)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/instadeep/lib/python3.8/site-packages/torch/nn/modules/module.py:1601\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_backward_pre_hooks\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1599\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m-> 1601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   1602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1603\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_transformernet(train_loader,model_train,optimizer,criterion,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instadeep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
