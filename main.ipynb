{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/instadeep/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import evaluate_gap,collate_batch_ptr,split_train_test\n",
    "from local_search import local_search_predict\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from multiprocessing import get_context\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else  \"cpu\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metric\n",
    "\n",
    "**Gap**: $100*\\frac{model\\_time - optimal\\_time}{optimal\\_time}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = np.load('data/instances.npy')\n",
    "instances_orders = np.load('data/instances_orders_unpadded.npy')\n",
    "\n",
    "X,y = instances,instances_orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import unpad\n",
    "\n",
    "for seq in y:\n",
    "    seq = unpad(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/instances_orders_unpadded.npy',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset,test_dataset = split_train_test(X,y,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving TSP with Local Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [03:47<00:00,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE GAP FOR LOCAL SEARCH SOLVER: 10.819183554028097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = []\n",
    "total_gaps = 0\n",
    "total = 0\n",
    "\n",
    "for x,y in tqdm(test_dataloader,total = len(test_dataloader)):\n",
    "    total += len(y)\n",
    "\n",
    "    with get_context(\"spawn\").Pool() as pool:\n",
    "                        preds = pool.map(\n",
    "                            local_search_predict,x)\n",
    "                        gaps = pool.starmap(\n",
    "                                evaluate_gap, list(zip(preds,y,x))\n",
    "                                \n",
    "                        )\n",
    "    y_preds.append(preds)\n",
    "    total_gaps+= np.sum(gaps)\n",
    "    \n",
    "print(f\"AVERAGE GAP FOR LOCAL SEARCH SOLVER: {total_gaps/total}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PointerNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pointernet import PointerNet\n",
    "from Data_Generator import TSPDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 10.0\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointerNet(128,\n",
    "                   512,\n",
    "                   2,\n",
    "                   0.1,\n",
    "                   False).to(DEVICE)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=collate_batch_ptr)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=collate_batch_ptr)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ptr(dataloader, model, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    total_loss,total_gap, total_count = 0,0,0\n",
    "    log_interval = 100\n",
    "\n",
    "    for idx, (x, y) in tqdm(enumerate(dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        total_count += y.shape[0]\n",
    "\n",
    "        y_pred,pointers = model(x)\n",
    "        y_pred =  y_pred.contiguous().view(-1, y_pred.size()[-1])\n",
    "\n",
    "        # Get the loss\n",
    "        loss = criterion(y_pred,y.view(-1))\n",
    "        total_loss  += loss.item()\n",
    "        # Do back propagation\n",
    "        loss.backward()\n",
    "        # Clip the gradients at 0.1\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        # Do an optimization step\n",
    "        optimizer.step()\n",
    "        for i,pred in enumerate(pointers.cpu().detach().numpy()):\n",
    "            total_gap += evaluate_gap(pred,y[i].cpu().detach().numpy(),x[i].cpu())\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches\"\n",
    "                \"| gap {:8.3f}\".format(epoch, idx, len(dataloader), total_gap / total_count),\n",
    "                f\"| loss {total_loss/total_count}\"\n",
    "            )\n",
    "            total_gap, total_count,total_loss = 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:14,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   100/ 6104 batches| gap  325.773 | loss 0.24334930311335196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "202it [00:28,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 6104 batches| gap  235.157 | loss 0.24059342756867408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "302it [00:42,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   300/ 6104 batches| gap  182.948 | loss 0.24015025556087494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "402it [00:56,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   400/ 6104 batches| gap  182.614 | loss 0.24019079595804216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "502it [01:09,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 6104 batches| gap  178.694 | loss 0.2401286005973816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "602it [01:23,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   600/ 6104 batches| gap  179.220 | loss 0.24015876784920692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "702it [01:37,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   700/ 6104 batches| gap  177.842 | loss 0.24009680598974228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "802it [01:50,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   800/ 6104 batches| gap  178.359 | loss 0.24014517799019813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "902it [02:04,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   900/ 6104 batches| gap  180.606 | loss 0.240131703466177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1002it [02:17,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1000/ 6104 batches| gap  181.320 | loss 0.24014682367444037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1102it [02:31,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1100/ 6104 batches| gap  182.047 | loss 0.2401750786602497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1202it [02:45,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1200/ 6104 batches| gap  179.624 | loss 0.24014060005545615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1302it [02:58,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1300/ 6104 batches| gap  180.075 | loss 0.24013905555009843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1402it [03:12,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1400/ 6104 batches| gap  177.308 | loss 0.24009154081344605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1502it [03:25,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1500/ 6104 batches| gap  179.320 | loss 0.24012700960040093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1602it [03:39,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1600/ 6104 batches| gap  178.793 | loss 0.24011190518736839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1702it [03:53,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1700/ 6104 batches| gap  178.009 | loss 0.2401067355275154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1802it [04:06,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1800/ 6104 batches| gap  180.114 | loss 0.240157400816679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1902it [04:20,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1900/ 6104 batches| gap  179.968 | loss 0.24013749718666078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2002it [04:34,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2000/ 6104 batches| gap  179.143 | loss 0.24015621468424797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2102it [04:47,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2100/ 6104 batches| gap  179.149 | loss 0.2401327085494995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2202it [05:01,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2200/ 6104 batches| gap  179.825 | loss 0.24016933888196945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2302it [05:15,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2300/ 6104 batches| gap  176.489 | loss 0.24011612862348555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2402it [05:29,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2400/ 6104 batches| gap  176.656 | loss 0.24011454969644547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2502it [05:42,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2500/ 6104 batches| gap  177.453 | loss 0.24010494872927665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2602it [05:56,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2600/ 6104 batches| gap  176.383 | loss 0.24008111655712128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2702it [06:09,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2700/ 6104 batches| gap  175.711 | loss 0.24008295834064483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2802it [06:23,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2800/ 6104 batches| gap  178.059 | loss 0.2401403945684433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2848it [06:29,  7.30it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, NUM_EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m     epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrain_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#accu_val = evaluate(valid_dataloader, model)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#scheduler.step()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m59\u001b[39m)\n",
      "Cell \u001b[0;32mIn[28], line 10\u001b[0m, in \u001b[0;36mtrain_ptr\u001b[0;34m(dataloader, model, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      8\u001b[0m total_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m y_pred,pointers \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m  y_pred\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, y_pred\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Get the loss\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/instadeep/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/TSP_DL/pointernet.py:317\u001b[0m, in \u001b[0;36mPointerNet.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     decoder_hidden0 \u001b[38;5;241m=\u001b[39m (encoder_hidden[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    316\u001b[0m                        encoder_hidden[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 317\u001b[0m (outputs, pointers), decoder_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mdecoder_input0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mdecoder_hidden0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m  outputs, pointers\n",
      "File \u001b[0;32m/opt/conda/envs/instadeep/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/TSP_DL/pointernet.py:231\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, embedded_inputs, decoder_input, hidden, context)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# Recurrence loop\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(input_length):\n\u001b[0;32m--> 231\u001b[0m     h_t, c_t, outs \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m (h_t, c_t)\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# Masking selected inputs\u001b[39;00m\n",
      "File \u001b[0;32m~/TSP_DL/pointernet.py:225\u001b[0m, in \u001b[0;36mDecoder.forward.<locals>.step\u001b[0;34m(x, hidden)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# Attention section\u001b[39;00m\n\u001b[1;32m    224\u001b[0m hidden_t, output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt(h_t, context, torch\u001b[38;5;241m.\u001b[39meq(mask, \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m--> 225\u001b[0m hidden_t \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_t\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_t, c_t, output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_ptr(train_dataloader, model, optimizer, criterion, epoch)\n",
    "    #accu_val = evaluate(valid_dataloader, model)\n",
    "    #scheduler.step()\n",
    "    print(\"-\" * 59)\n",
    "    #print(\n",
    "    #    \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
    "    #    \"valid accuracy {:8.3f} \".format(epoch, time.time() - epoch_start_time, accu_val)\n",
    "    #)\n",
    "    #print(\"-\" * 59)\n",
    "\n",
    "#print(\"Checking the results of test dataset.\")\n",
    "#accu_test = evaluate(test_dataloader, model)\n",
    "#print(\"test accuracy {:8.3f}\".format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformernet import TSP_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset,\n",
    "                        batch_size=16,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=collate_batch_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train = TSP_net(2, 128, 512, \n",
    "              6, 2, 8, 1000,\n",
    "              False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 50, 2])\n",
      "tensor([37, 30,  3, 28,  5, 26, 27,  1, 24, 29, 19, 21, 31,  9, 20, 22, 35, 23,\n",
      "         4, 14, 11, 34,  7, 16, 33,  2, 17,  6, 12,  8, 32, 36, 10, 15, 18, 45,\n",
      "        40, 25, 13,  0, 48, 43, 42, 46, 39, 47, 38, 44, 41, 49])\n",
      "tensor([ 0, 10, 15, 31, 27,  3, 13, 18, 22, 29, 24, 12, 17, 14,  2, 33, 23, 36,\n",
      "        20,  4, 16,  1, 11, 26, 30, 28,  9, 32, 21,  6, 34, 35,  7,  8, 25, 19,\n",
      "         5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "tensor([[ 0.0043,  0.0529],\n",
      "        [ 0.5244,  0.9983],\n",
      "        [ 0.2644,  0.6819],\n",
      "        [ 0.1576,  0.4723],\n",
      "        [ 0.3675,  0.9451],\n",
      "        [ 0.1551,  0.1053],\n",
      "        [ 0.7382,  0.5765],\n",
      "        [ 0.7900,  0.0018],\n",
      "        [ 0.7367,  0.0015],\n",
      "        [ 0.9485,  0.9472],\n",
      "        [ 0.0513,  0.3122],\n",
      "        [ 0.5290,  0.7354],\n",
      "        [ 0.5295,  0.3148],\n",
      "        [ 0.2128,  0.4243],\n",
      "        [ 0.3147,  0.4225],\n",
      "        [ 0.1025,  0.3678],\n",
      "        [ 0.4738,  1.0000],\n",
      "        [ 0.5299,  0.4747],\n",
      "        [ 0.2073,  0.2626],\n",
      "        [ 0.4201,  0.1540],\n",
      "        [ 0.1073,  0.8939],\n",
      "        [ 0.7903,  0.6874],\n",
      "        [ 0.3680,  0.3139],\n",
      "        [ 0.0514,  0.7836],\n",
      "        [ 0.5246,  0.2657],\n",
      "        [ 0.5773,  0.0505],\n",
      "        [ 0.6847,  0.7877],\n",
      "        [ 0.0517,  0.4221],\n",
      "        [ 0.7389,  0.9465],\n",
      "        [ 0.4183,  0.3169],\n",
      "        [ 0.7867,  0.7869],\n",
      "        [ 0.0562,  0.3703],\n",
      "        [ 0.9445,  0.6348],\n",
      "        [ 0.2679,  0.7397],\n",
      "        [ 0.8417,  0.4754],\n",
      "        [ 0.8970,  0.2083],\n",
      "        [ 0.0527,  0.8437],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000]])\n"
     ]
    }
   ],
   "source": [
    "for x, y in test_loader:\n",
    "    print(x.shape)\n",
    "    y_pred = model_train(x)\n",
    "    print(y_pred[0][1])\n",
    "    print(y[1])\n",
    "    print(x[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instadeep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
