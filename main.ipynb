{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import evaluate_gap,collate_batch_ptr\n",
    "from local_search import local_search_predict\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from multiprocessing import get_context\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else  \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metric\n",
    "\n",
    "**Gap**: $100*\\frac{model\\_time - optimal\\_time}{optimal\\_time}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = np.load('data/instances.npy')\n",
    "instances_orders = np.load('data/instances_orders_unpadded.npy')\n",
    "\n",
    "X,y = instances,instances_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  3,  2,  7,  4,  5, 10, 15, 11, 17,  1,  8, 13, 18,  9,  6, 16,\n",
       "       19, 12, 14, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1234]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import unpad\n",
    "\n",
    "for seq in y:\n",
    "    seq = unpad(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/instances_orders_unpadded.npy',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "train_dataset = list(zip(X_train,y_train))\n",
    "test_dataset = list(zip(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving TSP with Local Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [03:47<00:00,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE GAP FOR LOCAL SEARCH SOLVER: 10.819183554028097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = []\n",
    "total_gaps = 0\n",
    "total = 0\n",
    "\n",
    "for x,y in tqdm(test_dataloader,total = len(test_dataloader)):\n",
    "    total += len(y)\n",
    "\n",
    "    with get_context(\"spawn\").Pool() as pool:\n",
    "                        preds = pool.map(\n",
    "                            local_search_predict,x)\n",
    "                        gaps = pool.starmap(\n",
    "                                evaluate_gap, list(zip(preds,y,x))\n",
    "                                \n",
    "                        )\n",
    "    y_preds.append(preds)\n",
    "    total_gaps+= np.sum(gaps)\n",
    "    \n",
    "print(f\"AVERAGE GAP FOR LOCAL SEARCH SOLVER: {total_gaps/total}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PointerNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pointernet import PointerNet\n",
    "from Data_Generator import TSPDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.1\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointerNet(128,\n",
    "                   512,\n",
    "                   2,\n",
    "                   0.1,\n",
    "                   False)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                        batch_size=10,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=collate_batch_ptr)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ptr(dataloader, model, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    total_loss,total_gap, total_count = 0,0,0\n",
    "    log_interval = 100\n",
    "\n",
    "    for idx, (x, y) in tqdm(enumerate(dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred,pointers = model(x)\n",
    "        y_pred =  y_pred.contiguous().view(-1, y_pred.size()[-1])\n",
    "\n",
    "        # Get the loss\n",
    "        loss = criterion(y_pred,y.view(-1))\n",
    "        total_loss  += loss.item()\n",
    "        # Do back propagation\n",
    "        loss.backward()\n",
    "        # Clip the gradients at 0.1\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        # Do an optimization step\n",
    "        optimizer.step()\n",
    "        for i,pred in enumerate(pointers.detach().numpy()):\n",
    "            total_gap += evaluate_gap(pred,y[i].detach().numpy(),x[i])\n",
    "        total_count += len(y)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| gap {:8.3f}\".format(epoch, idx, len(dataloader), total_gap / total_count)\n",
    "                \"| loss {:8.3f}\".format(epoch, idx, len(dataloader), total_loss / total_count)\n",
    "            )\n",
    "            total_gap, total_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [01:01,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   100/ 1085 batches | gap  250.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [02:04,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 1085 batches | gap  363.790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "233it [02:23,  1.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 15\u001b[0m, in \u001b[0;36mtrain_ptr\u001b[0;34m(dataloader, model, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred,y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Do back propagation\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Clip the gradients at 0.1\u001b[39;00m\n\u001b[1;32m     17\u001b[0m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/instadeep/lib/python3.8/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/instadeep/lib/python3.8/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_ptr(test_loader,model,optimizer,criterion,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data points 2/10:   0%|          | 0/10 [00:00<?, ?data/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data points 10/10: 100%|██████████| 10/10 [00:00<00:00, 396.51data/s]\n",
      "Solved 10/10: 100%|██████████| 10/10 [00:00<00:00, 1189.37solve/s]\n",
      "  0%|          | 0/5 [00:00<?, ?Batch/s]/Users/aymenkallala/miniconda3/envs/instadeep/lib/python3.8/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "/Users/aymenkallala/Desktop/Columbia/instadeep_assignment/pointernet.py:246: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/IndexingUtils.h:28.)\n",
      "  decoder_input = embedded_inputs[embedding_mask.data].view(batch_size, self.embedding_dim)\n",
      "  0%|          | 0/5 [00:11<?, ?Batch/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = TSPDataset(10,\n",
    "                     5)\n",
    "\n",
    "dataloader = DataLoader(dataset,\n",
    "                        2,\n",
    "                        shuffle=True,\n",
    "                        num_workers=4)\n",
    "\n",
    "\n",
    "iterator = tqdm(dataloader, unit='Batch')\n",
    "\n",
    "for i_batch, sample_batched in enumerate(iterator):\n",
    "        train_batch = Variable(sample_batched['Points'])\n",
    "        target_batch = Variable(sample_batched['Solution'])\n",
    "\n",
    "        o, p = model(train_batch)\n",
    "        o = o.contiguous().view(-1, o.size()[-1])\n",
    "        target_batch = target_batch.view(-1)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 2])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 5])\n"
     ]
    }
   ],
   "source": [
    "print(train_batch.shape)\n",
    "print(target_batch.shape)\n",
    "print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset,\n",
    "                        batch_size=16,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=collate_batch_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800])\n",
      "torch.Size([800, 50])\n"
     ]
    }
   ],
   "source": [
    "for x,y,dm in test_loader:\n",
    "    o, p = model(x)\n",
    "    o = o.contiguous().view(-1, o.size()[-1])\n",
    "    y = y.view(-1)\n",
    "\n",
    "    print(y.shape)\n",
    "    print(o.shape)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([800, 50])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.contiguous().view(-1, o.size()[-1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0535,  0.7385],\n",
       "         [ 0.4729,  0.2111],\n",
       "         [ 0.3706,  0.9471],\n",
       "         ...,\n",
       "         [-1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000]],\n",
       "\n",
       "        [[ 0.8966,  0.8418],\n",
       "         [ 0.7322,  0.2105],\n",
       "         [ 0.0556,  0.2626],\n",
       "         ...,\n",
       "         [ 0.2081,  0.0039],\n",
       "         [-1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000]],\n",
       "\n",
       "        [[ 0.4766,  0.0024],\n",
       "         [ 1.0000,  0.3169],\n",
       "         [ 0.1034,  0.0026],\n",
       "         ...,\n",
       "         [-1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.0000,  0.7893],\n",
       "         [ 0.4227,  0.4748],\n",
       "         [ 0.1039,  0.1589],\n",
       "         ...,\n",
       "         [-1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000]],\n",
       "\n",
       "        [[ 0.9445,  0.3713],\n",
       "         [ 0.5283,  0.9464],\n",
       "         [ 0.3177,  0.4223],\n",
       "         ...,\n",
       "         [-1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000]],\n",
       "\n",
       "        [[ 0.1066,  0.4695],\n",
       "         [ 0.9953,  0.7346],\n",
       "         [ 0.8970,  0.9462],\n",
       "         ...,\n",
       "         [-1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformernet import TSP_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset,\n",
    "                        batch_size=16,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=collate_batch_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train = TSP_net(2, 128, 512, \n",
    "              6, 2, 8, 1000,\n",
    "              False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 50, 2])\n",
      "tensor([37, 30,  3, 28,  5, 26, 27,  1, 24, 29, 19, 21, 31,  9, 20, 22, 35, 23,\n",
      "         4, 14, 11, 34,  7, 16, 33,  2, 17,  6, 12,  8, 32, 36, 10, 15, 18, 45,\n",
      "        40, 25, 13,  0, 48, 43, 42, 46, 39, 47, 38, 44, 41, 49])\n",
      "tensor([ 0, 10, 15, 31, 27,  3, 13, 18, 22, 29, 24, 12, 17, 14,  2, 33, 23, 36,\n",
      "        20,  4, 16,  1, 11, 26, 30, 28,  9, 32, 21,  6, 34, 35,  7,  8, 25, 19,\n",
      "         5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "tensor([[ 0.0043,  0.0529],\n",
      "        [ 0.5244,  0.9983],\n",
      "        [ 0.2644,  0.6819],\n",
      "        [ 0.1576,  0.4723],\n",
      "        [ 0.3675,  0.9451],\n",
      "        [ 0.1551,  0.1053],\n",
      "        [ 0.7382,  0.5765],\n",
      "        [ 0.7900,  0.0018],\n",
      "        [ 0.7367,  0.0015],\n",
      "        [ 0.9485,  0.9472],\n",
      "        [ 0.0513,  0.3122],\n",
      "        [ 0.5290,  0.7354],\n",
      "        [ 0.5295,  0.3148],\n",
      "        [ 0.2128,  0.4243],\n",
      "        [ 0.3147,  0.4225],\n",
      "        [ 0.1025,  0.3678],\n",
      "        [ 0.4738,  1.0000],\n",
      "        [ 0.5299,  0.4747],\n",
      "        [ 0.2073,  0.2626],\n",
      "        [ 0.4201,  0.1540],\n",
      "        [ 0.1073,  0.8939],\n",
      "        [ 0.7903,  0.6874],\n",
      "        [ 0.3680,  0.3139],\n",
      "        [ 0.0514,  0.7836],\n",
      "        [ 0.5246,  0.2657],\n",
      "        [ 0.5773,  0.0505],\n",
      "        [ 0.6847,  0.7877],\n",
      "        [ 0.0517,  0.4221],\n",
      "        [ 0.7389,  0.9465],\n",
      "        [ 0.4183,  0.3169],\n",
      "        [ 0.7867,  0.7869],\n",
      "        [ 0.0562,  0.3703],\n",
      "        [ 0.9445,  0.6348],\n",
      "        [ 0.2679,  0.7397],\n",
      "        [ 0.8417,  0.4754],\n",
      "        [ 0.8970,  0.2083],\n",
      "        [ 0.0527,  0.8437],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000]])\n"
     ]
    }
   ],
   "source": [
    "for x, y in test_loader:\n",
    "    print(x.shape)\n",
    "    y_pred = model_train(x)\n",
    "    print(y_pred[0][1])\n",
    "    print(y[1])\n",
    "    print(x[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instadeep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
